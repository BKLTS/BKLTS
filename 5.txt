&&&&&&&5.Multi-Target Tracking Considering the Uncertainty of Deep
Learning-based Object Detection of Marine Radar Images
Eunghyun Kim1, Jonghwi Kim2, and Jinwhan Kim2
Abstract—In this paper, a multi-target tracking approach
that integrates the extended Kalman filter and deep learningbased
object detection in marine radar images is presented.
The Gaussian YOLOv3 method is utilized for object detection,
providing both position measurements and their uncertainties.
The extended Kalman filter is employed to estimate the position,
heading, and speed of each detected target considering the
uncertainty values obtained from the object-detection process.
The global nearest neighbor-based data association and a dual
filter structure composed of a confirmed track and a reserved
track are applied to enhance the robustness of the tracking
process. The feasibility of the proposed algorithm is validated
through a real-world marine radar dataset collected in a coastal
environment.
I. INTRODUCTION
In recent years, autonomous ships in the field of marine
robotics have seen remarkable growth in demand and
interest. This is due to their potential to perform various
tasks, such as coastal monitoring and accident response, in
a more cost-effective and efficient manner than traditional
manned ships. To guarantee the safety and efficiency of these
autonomous ships, it is crucial to have robust methods for
perceiving obstacles and motion estimation of target ships.
Among the various sensors used in maritime environments,
marine radar is a primary sensor in view of its capability
to detect distant obstacles under diverse weather conditions
and lighting scenarios, while maintaining a high degree of
reliability. However, to guarantee the accuracy of the radar
data, it is critical to differentiate targets from the noise
generated by marine clutter.
Recently, deep learning has been spotlighted to be an
effective approach to solving complex problems in computer
vision. The use of deep learning algorithms for object detection
in marine radar images is a natural choice due to their
ability to learn complex patterns for differentiating between
targets from the noise. Several studies have explored the
utilization of deep learning-based object detection of marine
radar[1], [2].
Furthermore, in addition to object detection, motion analysis
of the targets is also important. An extended Kalman
filter (EKF) using marine radars is commonly used for multitarget
tracking in marine environments, as it can effectively
handle nonlinear dynamics and incorporate measurements
from radar sensors. The EKF provides optimal state estimates
of multiple targets by using a statistical model of the
1Robotics Program, KAIST, Daejeon, 34141, Korea
olohyun@kaist.ac.kr
2The Department of Mechanical Engineering, KAIST, Daejeon, 34141,
Korea (stkimjh, jinwhan)@kaist.ac.kr
Fig. 1: Network architecture of Gaussian YOLOv3
uncertainty in the measurements and model.
In the measurement update stage of the EKF, it is important
to implement a method for determining uncertainty
values. There are several methods available, including experimental
evaluation or tuning of existing deep learning
algorithms, or obtaining the uncertainty value together with
the result value. Incorporating the uncertainty obtained from
deep learning into the EKF can improve the precision and
stability of multi-target tracking in marine environments. In
multi-target tracking scenarios, deep learning enables the
update of different uncertainties for each target, as opposed
to other methods that apply the same uncertainty value to all
targets.
There are several pieces of research dealing with uncertainty
in deep learning in computer vision. Gal et al. [3]
provides a Bayesian approximation of model uncertainty
using dropout, a widely used regularization technique in
deep learning. Kendall et al. [4] modeled both aleatoric
and epistemic uncertainties and showed that this leads to
improved performance on several computer vision tasks.
However, previous studies have mainly focused on predicting
the level of uncertainty while not utilizing the uncertainty of
the measured values. To address this issue, Kim et al. [5]
incorporate particle filter and Gaussian YOLOv3[6] which
models the localization uncertainty for tracking ships from
the camera sensor. Inspired by this paper, we integrate
adapting Gaussian YOLOv3 to marine radar with the EKF
framework. Gaussian YOLOv3 predicted localization uncertainty
by Gaussian modeling and reconstruction loss function
of YOLOv3[7]. Compared to previous studies, this study
estimated each actual measurement uncertainty for detected
objects in one scene, rather than using predefined static
2023 20th International Conference on Ubiquitous Robots (UR)
June 25-28, 2023. Hawaii Convention Center, Honolulu, Hawaii
979-8-3503-3517-0/23/$31.00 ©2023 IEEE 191
2023 20th International Conference on Ubiquitous Robots (UR) | 979-8-3503-3517-0/23/$31.00 ©2023 IEEE | DOI: 10.1109/UR57808.2023.10202163
Authorized licensed use limited to: Harbin Engineering Univ Library. Downloaded on October 20,2023 at 12:29:28 UTC from IEEE Xplore. Restrictions apply.
uncertainty. Additionally, to distinguish whether measurements
are the existing track or the new track, a dual-track
filter structure and the global nearest neighbor (GNN)-based
data association[8], [9] were employed. The validation of
the proposed method was conducted on a real-world marine
radar dataset obtained in coastal environments[10].
II. PROPOSED METHOD
A. Object Detection with Uncertainty using Gaussian
YOLOv3
Among the commonly used detection algorithms based
on YOLO, we adopted Gaussian YOLOv3 because of its
ability to estimate uncertainty. The Gaussian YOLOv3[6]
models the position and size of the object detection result as
Gaussian distributions. The network architecture of Gaussian
YOLOv3 is shown in Fig. 1. The result of detection is
shown in Fig. 2. The training set and test set consist of 509
and 80 images, respectively, and all images were manually
annotated. To augment the dataset, the images transformed
horizontal, vertical, and 90◦ rotations. In Fig. 2-(a), marine
radar images are displayed as inputs. The result of the
input after inference through the detection layer is shown in
Fig. 2-(b). The outputs illustrated the mean (μ) by a center
point within the bounding box and variance (Σ) depicted by
crossed lines inside the boxes for each coordinate (x, y). Additionally,
the size of the bounding box (w, h) is represented
by solid lines and predicted uncertainties of box sizes are
indicated by dashed lines around the boxes.
This result was obtained by adjusting the loss function of
YOLOv3[7] to incorporate mean and variance parameters as
follows:
Lx = −ΣW i=1ΣHj
=1ΣKk
=1γijk log(N(xG
ijk|μtx (xijk),Σtx (xijk) + ϵ)),
(1)
where Lx is the negative log likelihood loss function, W, H
are the number of grids of each width and height, K is the
number of anchors, γijk is the parameter from ground truth
bounding box size, N means normal distribution, μtx (xijk)
is the output of the detection layer at the k-th anchor in
(a) Input (b) Output
Fig. 2: Example of object detection: It represented position
by a center point and size by bounding box. Predicted
uncertainties of box center coordinates are visualized by
crossed lines inside the boxes and uncertainties of box sizes
are represented by dashed lines around the boxes.
(a) Clear edge image object
has low uncertainty of position
(b) Blurry edge image object
has high uncertainty of position
Fig. 3: Comparison of detection results for images with the
same object(ship) but different blurring in other scenes
the (i,j) grid, Σtx (xijk) is the output of detection layer,
indicating uncertainty of coordinate, xG
ijk is the ground truth
of coordinate, and the ϵ is 10−9 that assigned value for
numerical stability of the logarithmic function. The others
(i.e., Ly, Lw, and Lh) are the same as Lx except for each
parameter. The high noise in the learning data results in an
increase in the loss, and the model adjusts by increasing the
variance(Σ) to decrease the loss.
This approach explains effectively marine radar image
detection scenarios, where the same object in different scenes
can appear distinct in some images and blurred in others.
As a result, this approach captures some scenes where the
objects with a more blurry edge elevate uncertainty in their
position. Fig. 3 (a) and (b) reflect this tendency, showing
that more clear object image leads to the low uncertainty of
the object’s position increasing accordingly. In Fig. 3 (b), A
blurry edge shape object image gets a high uncertainty of
position results which is illustrated with long crossed lines
inside the boxes.
B. Dual Filter Structure and Data Association Method
After the targets are detected from the radar image, they
are used as measurements of the tracking filter. The dual
filter structure and GNN-based data association make use
of the distinctive strengths of marine radar, such as its
resilience in tough weather conditions and its high-resolution
range, to achieve precise target tracking in complex and
cluttered environments. Additionally, it exhibits robustness
to challenging marine tracking scenarios, including false
detections, target merging, and splitting.
The tracking algorithm is structured with a dual track
system consisting of reserved and confirmed tracks [9]. The
phase conversion of a reserved track to a confirmed track
is contingent upon the fulfillment of the traditional M-of-
N rule, which requires the detection of the target in N
or more out of the total M observation scenes. For those
tracks that have been converted to confirmed tracks using
the M-of-N rule, the motion estimation is started using
the EKF-based tracking filter. When the uncertainty level
in the position exceeds a predefined value, the tracking is
terminated and deleted. This approach alleviates false detections
and missed targets, and enhances the performance of
192
Authorized licensed use limited to: Harbin Engineering Univ Library. Downloaded on October 20,2023 at 12:29:28 UTC from IEEE Xplore. Restrictions apply.
Fig. 4: The multiple target tracking process using dual filter
structure flowchart
multi-target tracking systems through efficient management
of track initialization and deletion. The overall scheme is
shown in Fig. 4.
The newly detected target measurements are matched with
the existing targets in the filter through the utilization of
the GNN-based data association [8]. They are associated
when the Mahalanobis distance between them is lower than
a predefined ellipsoidal gate as follows:
d =
p
˜z′S−1˜z ≤ G, (2)
where the Mahalanobis distance d is the normalized statistical
distance, S is the measurement innovation covariance
matrix, G is a predefined gate, and ˜z is the measurement
innovation vector which is defined by the difference between
the expected measurement estimated by the filter and measurement
results. Because multiple measurements may lie
within the gates of multiple tracks, the track with the smallest
Mahalanobis distance to the measurement is selected as the
best match.
C. Target Tracking using EKF
The EKF is a widely used algorithm for estimating the
state of a dynamic system in real-time. One of the primary
advantages of the EKF is its robustness in measurement noise
and non-linearities in the system model. The EKF iteratively
updates its estimate of the system state by predicting the
state based on the previous estimate and then correcting the
prediction based on the measurement. Thus, by correcting
the prediction by detection results with uncertainty in deep
learning results as described in Section II-A
The motion of targets is predicted through the application
of an EKF by a constant velocity model. The filter structure
utilizes a three-degrees-of-freedom (3DOF) kinematic model
to describe the movements of the detected targets.
In order to estimate multi targets, the state vector of the
tracking filter structure is augmented by cascading the target
state vector as follows:
xT = [x⊤T1 x⊤T2 . . . ]⊤, (3)
where the ith registered state vector is xTi .
xTi is represented as follows:
xTi = [xTi yTi ψTi VTi ]⊤, (4)
where xTi and yTi are the positions in the global frame, ψTi
is the heading angle, and VTi is the speed of target. The
equations of the motion for the filter’s kinematics can be
described as follows:
˙xTi = [VTi cos ψTi VTi sin ψTi 0 0]⊤ + w, (5)
where w is the zero-mean Gaussian process noise which
reflects the uncertainty of the motion model.
The measurement model for updating the filter is expressed
as follows:
zj = [zxj zyj ]⊤ + v, (6)
where zxj and zyj represent the jthx, y position of the
bounding box, v = [vxj vyj ]⊤ denotes the positional uncertainty
of the bounding box obtained from the results in
Section II-A. These measurements are updated based on
the results of the data association procedure outlined in
Section II-B, which determines whether they correspond to
an existing track or a new reserved track.
III. RESULT
The feasibility of the proposed algorithm was verified
through its application to experimental data obtained near
Suyeong Bay in Busan [10]. The ship was equipped with
GPS, compass, and radar, and the sensor measurements
were synchronized at a rate of 0.5 Hz. Two representative
scenes, depicted in Fig. 5 and Fig. 6, were selected to
demonstrate the feasibility of the algorithm. The red dashed
lines represent estimated target trajectories, black circles
show the AIS data of each target ship. The blue dashed line
represents own ship’s trajectory which was obtained by GPS,
while the measurements from marine radar images obtained
using Gaussian YOLOv3 were represented by magenta dots.
The first scene as shown in Fig. 5 depicts a situation in
which a target ship crosses in front of the own ship. In this
scene, it was possible to observe that the tracking algorithm
was accurate and stable. The second scene as shown in Fig. 6
shows ships moving in a straight line being captured by the
radar while the own ship was rotating near a floating object
without AIS data. The results show that the target ships were
tracked accurately despite the dynamic movements of the
own ship.
A constant offset of approximately 30 m can be observed
when comparing the estimated target trajectories to the AIS
data, which may have been caused by the incorrect radar
installation location or the large size of the target ships.
However, the offset remained consistent, indicating that the
targets were being tracked accurately.
The results demonstrate the efficiency of combining measurements
with uncertainty from deep learning and EKF for
multi-target tracking in marine environments. The figures
confirm that all targets follow the AIS data and their states
were accurately estimated.
193
Authorized licensed use limited to: Harbin Engineering Univ Library. Downloaded on October 20,2023 at 12:29:28 UTC from IEEE Xplore. Restrictions apply.
Fig. 5: Result of tracking target ship with crossing situation
in global coordinates
IV. CONCLUSIONS
In this research, we demonstrate the efficiency of integrating
deep learning-based object detection with the EKF for
multi-target tracking in marine environments. The Gaussian
YOLOv3 algorithm was employed to detect target positions
and uncertainties for the purpose of tracking. The proposed
method employs a GNN-based data association and a dualtrack
structure to achieve robustness and efficiency. The
performance of the proposed approach was evaluated on
a real-world marine radar dataset. The results showed that
the proposed approach achieved stable and constant tracking
performance, demonstrating the potential of this integration
for marine autonomous systems.
V. ACKNOWLEDGEMENT
This is supported by the ’Autonomous Ship Technology
Development Program(20011722, Development of a Situational
Awareness System for Preventing Collisions and
Accidents of Autonomous Ships)’ funded by the Ministry
of Trade, Industry & Energy(MOTIE, Korea).
